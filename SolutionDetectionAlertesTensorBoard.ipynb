{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/SolutionDetectionAlertesTensorBoard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qF8xmpAdACr"
   },
   "source": [
    "# Détection d'alertes par réseaux de neurones\n",
    "\n",
    "Dans cet exercice, le but est de créer un système très basique de détection de messages douteux  par Réseaux de Neurones en se basant uniquement sur des mots clés trouvés dans les sujets de mails.\n",
    "\n",
    "Une version plus évoluée étudierait aussi le texte transformé en sac de mots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*L’observation du contenu des communications par les gouvernements dans un but de sécurité permettrait de détecter les mails potentiellement dangereux et de lever des alertes.\n",
    "Cependant la masse d’information échangée est trop importante pour garantir une bonne analyse.\n",
    "Des réseaux de neurones peuvent être utilisés pour guider la détection de problèmes potentiels.*\n",
    "\n",
    "*Il s’agit donc ici de définir un réseau de neurones et de lui faire apprendre à détecter des textes à risque.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les exemples d’apprentissage seront constitués :\n",
    "- d’une série de valeurs indiquant si oui ou non un terme est présent dans le texte analysé,\n",
    "- de la réponse attendue (dans la ligne danger)\n",
    "\n",
    "Pour chaque texte, des mots-clés sont détectés, et le danger potentiel du texte est indiqué. Voici les exemples d’apprentissage :\n",
    " - 'bombe', 'feu' => danger\n",
    " - 'bombe', 'patisserie' => _\n",
    " - 'bombe', 'acide' => danger\n",
    " - 'bombe', 'canon' => danger\n",
    " - 'fille', 'canon' => _\n",
    " - 'mec', 'canon' => _\n",
    " - 'patisserie', 'acide' => _\n",
    " - 'canon', 'balle' => danger\n",
    " - 'balle', 'tennis' => _\n",
    " - 'fille', 'acide' => danger\n",
    " \n",
    " Il faut transformer cela en un ensembles de vecteurs d'entrées et de sorties.\n",
    "\n",
    "| bombe | feu | patisserie | fille | canon | mec | acide | balle | tennis | *danger* |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| 1., | 1., | 0., | 0., | 0., | 0., | 0., | 0., | 0. |  1  |\n",
    "| 1., | 0., | 0., | 0., | 0., | 0., | 1., | 0., | 0. |  1  |\n",
    "| 1., | 0., | 0., | 0., | 1., | 0., | 0., | 0., | 0. |  1  |\n",
    "| 0., | 0., | 0., | 0., | 1., | 0., | 0., | 1., | 0. |  1  |\n",
    "| 0., | 0., | 0., | 1., | 0., | 0., | 1., | 0., | 0. |  1  |\n",
    "| 1., | 0., | 1., | 0., | 0., | 0., | 0., | 0., | 0. |  0  |\n",
    "| 0., | 0., | 0., | 1., | 1., | 0., | 0., | 0., | 0. |  0  |\n",
    "| 0., | 0., | 0., | 0., | 1., | 1., | 0., | 0., | 0. |  0  |\n",
    "| 0., | 0., | 1., | 0., | 0., | 0., | 1., | 0., | 0. |  0  |\n",
    "| 0., | 0., | 0., | 0., | 0., | 0., | 0., | 1., | 1. |  0  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZpJB9iOdRS3"
   },
   "source": [
    "---\n",
    "## Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odDg9S7xdFsv"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "#pour les graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "#SI bug plus loin lors du dessin des graphiques, ajouter ces 2 lignes\n",
    "#import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### installation du tableau de bord tensorflow pour étudier l'apprentissage\n",
    "Enregistre des données sur l'évolution des performances dans un fichier log qui sera visualisé par des outils graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Chargement du tableau de bord tensorflow\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#besoin du package sur les dates\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efface tous les anciens logs (attention au repertoire)\n",
    "%rm -rf ./alertesLogs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XN8WXXdTdXx0"
   },
   "source": [
    "---\n",
    "\n",
    "### Définir les entrées et sorties attendues\n",
    "\n",
    "Les entrées correspondent à la présence des mots clés par dans les textes.\n",
    "Ici, les entrées d'apprentissage sont consituées de 70% de l'exemple présenté (donc 7 lignes de  9 valeurs 0,1). Les sorties d'apprentissage correspondent au fait que chaque entrée soit un message dangereux ou non.\n",
    "\n",
    "Les entrées et sorties de validations sont donc constitués des 30% restants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1mjGN2Bb5Ki",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#transformer les données en entrées et sorties\n",
    "# attention, il vaut mieux rester entre 0 & 1, surtout pour la sortie !\n",
    "\n",
    "tableau = np.array([\n",
    "[1.,1.,0.,0.,0.,0.,0.,0.,0.,1], \n",
    "[1.,0.,0.,0.,0.,0.,1.,0.,0.,1], \n",
    "[1.,0.,0.,0.,1.,0.,0.,0.,0.,1], \n",
    "[0.,0.,0.,0.,1.,0.,0.,1.,0.,1], \n",
    "[0.,0.,0.,1.,0.,0.,1.,0.,0.,1], \n",
    "[1.,0.,1.,0.,0.,0.,0.,0.,0.,0], \n",
    "[0.,0.,0.,1.,1.,0.,0.,0.,0.,0], \n",
    "[0.,0.,0.,0.,1.,1.,0.,0.,0.,0], \n",
    "[0.,0.,1.,0.,0.,0.,1.,0.,0.,0], \n",
    "[0.,0.,0.,0.,0.,0.,0.,1.,1.,0]], float)\n",
    "\n",
    "keywords = (\"bombe\", \"feu\", \"patisserie\", \"fille\", \"canon\", \"mec\", \"acide\", \"balle\", \"tennis\")    \n",
    "nb_lignes = tableau.shape[0]\n",
    "nb_val = len(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on prend un pourcentage de lignes pour apprendre, le reste pour valider\n",
    "#on mélange les lignes pour pouvoir avoir des exemples d'apprentissage\n",
    "# et de validation homogènes (au cas où les exemples auraient été saisis dans un ordre précis)\n",
    "# mais le mieux est de mieux choisir ces exemples qui ont un impact important dans la qualité de l'apprentissage\n",
    "np.random.shuffle(tableau)\n",
    "\n",
    "#nb de lignes d'apprentissage\n",
    "nb_lignes_app = nb_lignes * 70 // 100\n",
    "#nb de lignes de validation\n",
    "nb_lignes_val = nb_lignes - nb_lignes_app\n",
    "\n",
    "# les premieres colonnes sont les entrees \n",
    "# la derniere colonne est la sortie\n",
    "\n",
    "#on remplit les entrees et sorties d'apprentissage\n",
    "entrees_app = tableau[0:nb_lignes_app, 0:nb_val]\n",
    "sorties_app = tableau[0:nb_lignes_app, nb_val:nb_val+1]\n",
    "\n",
    "#on remplit les entrees et sorties de validation\n",
    "entrees_val = tableau[nb_lignes_app:nb_lignes, 0:nb_val]\n",
    "sorties_val = tableau[nb_lignes_app:nb_lignes, nb_val:nb_val+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorties_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SC-1MnShdwe0",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### Choisir le modèle de réseau\n",
    "- ici les couches sont séquentielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbST4EmqcCdJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 11:39:35.520444: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jo5Ej8kkd8nh",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### Définir l'architecture du réseau\n",
    "Choisissez la struture du réseau, le nb de couches cachées, etc.\n",
    "- une première couche composée de \n",
    "  - autant de neurones en entrée que de mots clés, plus le neurone BIAS (ou non)\n",
    "  - x neurones en sortie \n",
    "- une dernière couche composée de\n",
    "  - y neurones en entrée (ceux de la couche précédente) et \n",
    "  - de 1 neurone en sortie (Spam ou non)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#une premiere couche constituée d'autant de neurones en entrée que de mots clés, 6 en sortie...\n",
    "model.add(Dense(4, use_bias=True, input_shape=(nb_val,), activation='tanh'))\n",
    "\n",
    "#une couche intermédiaire, 3 neurones en sortie et forcement 6 en entrees...\n",
    "model.add(Dense(4, use_bias=True, activation='sigmoid'))\n",
    "\n",
    "#une couche intermédiaire, 3 neurones en sortie et forcement 6 en entrees...\n",
    "model.add(Dense(4, use_bias=True, activation='sigmoid'))\n",
    "\n",
    "#une derniere couche constituée de 1 neurone en sortie, \n",
    "# nb neurones de la couche précédente en entrée et activation sigmoide\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8L4LxSBWeaF1",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### Compiler le  réseau\n",
    "- ici, on précise que l'algo de correction d'erreur est *'adam'*, et que l'erreur calculée est la moyenne des valeurs absolues des erreurs commises. On indique également que l'on veut voir apparaître en plus la précision de l'apprentissage (accuracy).\n",
    "\n",
    "(vous pouvez chosir un autre optimizer et un autre calcul de loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlnG97g7cQKW"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adamax', loss='MSE', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### <font color=\"red\">Ajout de la volonté d'enregistrer dans un log les etapes d'apprentissage</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 11:39:35.586931: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-04-25 11:39:35.586952: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-04-25 11:39:35.587001: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"alertesLogs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ4IQ-bIdtN1"
   },
   "source": [
    "---\n",
    "\n",
    "### Entraîner le réseau \n",
    "- ici on  le fait  'parler' (verbose=2) si le nb de cycles d'apprentissage (epochs) est court\n",
    "- <font color=\"red\">*Et on indique l'enregistreur de logs (callbacs)*</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "ddTla-J_cfz8",
    "outputId": "0fd3cade-cd59-41db-c5f6-0ea22e48cac0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 11:39:35.634467: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-25 11:39:36.470557: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-04-25 11:39:36.470574: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-04-25 11:39:36.472670: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2022-04-25 11:39:36.474355: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-04-25 11:39:36.476778: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36\n",
      "2022-04-25 11:39:36.477556: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36/MacBook-Pro-de-Emmanuel-2.local.trace.json.gz\n",
      "2022-04-25 11:39:36.479571: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36\n",
      "2022-04-25 11:39:36.479743: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36/MacBook-Pro-de-Emmanuel-2.local.memory_profile.json.gz\n",
      "2022-04-25 11:39:36.480462: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36Dumped tool data for xplane.pb to alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36/MacBook-Pro-de-Emmanuel-2.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36/MacBook-Pro-de-Emmanuel-2.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36/MacBook-Pro-de-Emmanuel-2.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36/MacBook-Pro-de-Emmanuel-2.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to alertesLogs/fit/20220425-113935/train/plugins/profile/2022_04_25_11_39_36/MacBook-Pro-de-Emmanuel-2.local.kernel_stats.pb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tests = model.fit(entrees_app, sorties_app, \n",
    "                    validation_data=(entrees_val, sorties_val),\n",
    "                    epochs=500, verbose=0,\n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0zBYIALlDYp",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Utilisation du tableau de bord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c696f35338eac3cf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c696f35338eac3cf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir alertesLogs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N38spzckmMMJ"
   },
   "source": [
    "---\n",
    "## Utilisation du réseau\n",
    "Quelle est la probabilité que les textes contenant les mots :\n",
    "1. bombe et feu\n",
    "2. mec patisserie feu\n",
    "\n",
    "soient des textes suspects ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.655429]]\n",
      "[[0.38988662]]\n"
     ]
    }
   ],
   "source": [
    "def build_input(mots):\n",
    "    inputs = np.zeros(len(keywords))\n",
    "    i = 0\n",
    "    for mot in mots:\n",
    "        inputs[tuple.index(keywords, mot)] = 1\n",
    "    return inputs\n",
    "\n",
    "input_test = build_input(( 'feu', 'bombe'))\n",
    "entreesTests = np.array([input_test], float)\n",
    "\n",
    "predictions = model.predict(entreesTests)\n",
    "print(predictions)\n",
    "\n",
    "input_test = build_input(('mec', 'patisserie', 'feu'))\n",
    "entreesTests = np.array([input_test], float)\n",
    "\n",
    "predictions = model.predict(entreesTests)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TestOUX.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
