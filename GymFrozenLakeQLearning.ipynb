{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/GymFrozenLakeQLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## Appliqué à [Gym.OpenAI](https://gym.openai.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test de ML par Q-Learning pour atteindre l'objectif\n",
    "\n",
    "**Utilisation de l'environnement Gym**\n",
    " (voir la page d'introduction à [Gym](https://gym.openai.com))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Si besoin, importer gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gym "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "#### L'environnement FrozenLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- Utiliser l'environnement `FrozenLake8x8-v1` (un labyrinthe en mode texte)\n",
    "  - **ATTENTION**, avec d'ancienne version de gym (sous colab, ...), il faut utiliser la version 0 (`FrozenLake8x8-v0`)- 4 actions sont possibles (Left(0), Down(1), Right(2), Up(3))\n",
    "  - l'adjectif \"Frozen\" signifie qu'une *action n'est pas déterministe !*\n",
    "    - à partir d'une case \"gelée\", aller à droite peut .. mener à droite, ou pas\n",
    "    - => intérêt du Q-Learning adapté à ce type d'environnement probabiliste\n",
    "- Le labyrinthe est ainsi composé de zones glacées, de puits, et d'un objectif\n",
    "\n",
    "\n",
    "**N.B.** \n",
    "  - *Cet environnement fonctionne bien sous colab, jupyterlab.. quelques soucis de l'affichage de l'état courant (carré rouge) sous Pyzo....* \n",
    "  - Il est fortement conseillé de débuter avec un environnement déterministe pour évaluer la bonne marche de l'algo de Q-Learning que vous aurez développer.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Etude de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specification de l'environnement :  EnvSpec(FrozenLake-v1)\n",
      "espace d'actions :  Discrete(4)  => 4 actions \"discretes\" (non continues)\n",
      "espace d'etats :  Discrete(16)  => 16 etats distincts\n",
      "Environnement et etat initial (en rouge) : \n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "S = Start (pos 0), G = Goal (pos 15), H = Hole, F = Frozen place\n",
      "Prendre une action au hasard : \n",
      "action choisie= 2 ; l'exécuter...\n",
      "nouvel état=1, recompense sur cet etat=0.0, etat final (trou ou but)=False, info={'prob': 1.0}\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=False) # tester FrozenLake8x8 pour l'environnement plus large\n",
    "print(\"specification de l'environnement : \", env.spec)\n",
    "print(\"espace d'actions : \", env.action_space , \" => 4 actions \\\"discretes\\\" (non continues)\") #ici 4 actions discrétisée\n",
    "print(\"espace d'etats : \", env.observation_space , \" => 16 etats distincts\") #ici 4x4 cellules possibles\n",
    "\n",
    "env.reset()\n",
    "print(\"Environnement et etat initial (en rouge) : \")\n",
    "env.render()\n",
    "print(\"S = Start (pos 0), G = Goal (pos 15), H = Hole, F = Frozen place\")\n",
    "\n",
    "print(\"Prendre une action au hasard : \")\n",
    "a = env.action_space.sample()\n",
    "print(\"action choisie=\",a,\"; l'exécuter...\")\n",
    "#on recupère des valeurs en retour\n",
    "new_s, reward, done, info = env.step(a)\n",
    "print(f\"nouvel état={new_s}, recompense sur cet etat={reward}, etat final (trou ou but)={done}, info={info}\")\n",
    "#note sous python 3.10, la version de gym retourne 5 valeurs : \n",
    "#new_s, reward, done, goal, info = env.step(a)\n",
    "#print(f\"nouvel état={new_s}, recompense sur cet etat={reward}, etat final (trou ou but)={done},etat but={goal}, info={info}\")\n",
    "\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Test des actions\n",
    "\n",
    "Sous Gym, `step` permet d'effectuer une action. \n",
    "En retour la fonction retourne une observation sur l'etat d'arrivee, sa recompense, son type (final ou non), et des informations.\n",
    "Ici, dans FrozenLake, \n",
    "- observation = position où se trouve l'agent\n",
    "- reward = recompense\n",
    "- done = vrai si but atteint\n",
    "- info = probabilité de succès de l'action \n",
    "  - en mode déterministe, sol non glissant, la proba de réussite est de 100%\n",
    "  - en mode non déterministe, sol glissant, la proba de réussite est de 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Cas non déterministe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 0 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "###### Test des actions\n",
    "env.reset()\n",
    "action = 0\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 4 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = 1\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 1 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = 2\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 0 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = 3\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Cas non déterministe**\n",
    "\n",
    "L'environnement FrozenLake peut également être chargé en mode non déterministe : chaque état est une case gelée, et chaque action qui s'y deroule n'a qu'une chance sur trois de réussir !\n",
    "\n",
    "Chargeons l'environnement dans ce mode et testons les actions à partir de l'état initial : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "pos° actuelle: 10 ,gain: 0.0 ,fini: False , {'prob': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=True) \n",
    "\n",
    "env.reset()\n",
    "env.env.s = 6\n",
    "action = 0\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "pos° actuelle: 10 ,gain: 0.0 ,fini: False , {'prob': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.env.s = 6\n",
    "action = 1\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "pos° actuelle: 10 ,gain: 0.0 ,fini: False , {'prob': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.env.s = 6\n",
    "action = 2\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Up)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 2 ,gain: 0.0 ,fini: False , {'prob': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.env.s = 6\n",
    "action = 3\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On est clairement ici dans un environnement non déterministe (une même action à partir d'un même état ne mène pas toujours au même résultat); c'est le contexte de prédilection de l'algo de Q-Learning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <font color=\"red\">Premiere résolution en mode déterministe</font>\n",
    "Important, pour valider l'apprentissage de votre algorithme avant de passer en mode non-déterministe, il vaut mieux le tester sur un environnement où chaque action à 100% de réussite. Ci-dessous un exemple sur le mini labyrinthe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 1 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 2 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "FH\u001b[41mF\u001b[0mH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 6 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "pos° actuelle: 10 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "pos° actuelle: 14 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "pos° actuelle: 15 ,gain: 1.0 ,fini: True , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "#solution = politique = suite d'actions menant à un but\n",
    "actions = [2,2,1,1,1,2]\n",
    "env.reset()\n",
    "for a in actions:\n",
    "    observation, reward, done, info = env.step(a)\n",
    "    env.render()\n",
    "    print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exemple d'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "env = gym.make('FrozenLake8x8-v1', is_slippery=False)\n",
    "actions = {0:'Gauche', 1:'Bas', 2:'Droite', 3:'Haut'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialiser la Q-Table\n",
    "# autant de cases que l'environnement en possède, \n",
    "# contenant autant de valeurs que d'actions possibles\n",
    "# donc ici une matrice 64 x 4\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place des paramètres\n",
    "Pour rappel l'algo de Q Learning simple repose sur cette équation : \n",
    "$Q(s,a) \\gets \\lambda \\times (r + \\gamma \\times max_{a'}(Q(s', a'))) + (1-\\lambda ) \\times Q(s,a)$ avec \n",
    "  - $\\lambda$ : coef d'apprentissage\n",
    "  - $\\gamma$ : coef de réduction \n",
    "  - $r$ : récompense\n",
    "  \n",
    "Cette équation donne la qualité de l'action *a* à partir de l'état *s*.\n",
    "\n",
    "Initialement, les actions sont choisies aléatoirement et notées; puis au fil des tests les actions les plus valuées sont choisies. Pour cela, un tirage est effectuée, s'il est inférieur à un $\\epsilon$, le choix est aléatoire. Cet $\\epsilon$ décroit au fil des tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_learn = .1\n",
    "gamma = 0.99\n",
    "epsilon = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupérer la meilleure action\n",
    "`argmax(tab)` retourne l'indice de la plus grande valeur du tableau.\n",
    "\n",
    "`argmax(Q[2])` retourne donc le no de l'action la plus intéressante à partir de l'état 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'algorithme de Q-Learning simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##algorithme de Q-Learning simple\n",
    "def q_learn(nb_actions=64):\n",
    "    \"\"\"\n",
    "    effectue un cycle d'apprentissage/recherche de solution' via le Q-Learning simple\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : no de l'etape\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    total_r : recompense totale\n",
    "    r : recompense du dernier etat rencontre\n",
    "    states_list : liste des etats traverses\n",
    "    actions_list : liste des actions effectuees\n",
    "\n",
    "    \"\"\"\n",
    "    s = env.reset()\n",
    "    #sous python 3.10, ajouter\n",
    "    #s = s[0]\n",
    "    total_r = 0\n",
    "    done = False\n",
    "    step = 0\n",
    "    states_list = []\n",
    "    actions_list = []\n",
    "    # The Q-Table learning algorithm\n",
    "    while not done and step < nb_actions:\n",
    "        step += 1\n",
    "        # Choose an action by greedily (with noise) picking from Q table\n",
    "        actions = Q[s, :]\n",
    "        if rnd.random()<epsilon or np.max(actions)==0:\n",
    "            a = rnd.randint(0, env.action_space.n-1)\n",
    "        else:\n",
    "            a = np.argmax(actions)\n",
    "\n",
    "        # Get new state and reward from environment\n",
    "        new_state, r, done, _ = env.step(a)\n",
    "\n",
    "        # Get negative reward every step\n",
    "        # if r == 0: r = -0.001\n",
    "\n",
    "        # Q-Learning\n",
    "        Q[s, a] = (1-lambda_learn)*Q[s, a] + lambda_learn*(r + gamma * np.max(Q[new_state, :]) - Q[s, a])\n",
    "        s = new_state\n",
    "        total_r = total_r + r\n",
    "        states_list.append(s)\n",
    "        actions_list.append(a)\n",
    "    return total_r, r, states_list, actions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_qlearn(nb_episodes = 4000, nb_actions = 64):\n",
    "    \"\"\"\n",
    "    lance nb_episodes fois un cycle de Q-Learning et memorise chaque solution trouvee\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    solutions_list : liste des solutions (no, recompense totale, liste des etats, liste des actions)\n",
    "    \"\"\"\n",
    "    global epsilon\n",
    "    states_list = []\n",
    "    actions_list = []\n",
    "    solutions_list = []\n",
    "    epsilon = 1\n",
    "    for i in range(nb_episodes):\n",
    "        # Reset environment and get first new observation\n",
    "        total_r, r, states_list, actions_list = q_learn()\n",
    "        epsilon = epsilon * 0.999\n",
    "        # memorize if a solution has been found\n",
    "        if r == 1: solutions_list.append((i, total_r, states_list, actions_list))\n",
    "        \n",
    "    if(len(solutions_list) == 0): print(\"aucune solution trouvee !!\")\n",
    "    return solutions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage de du résultat\n",
    "Affichons maintenant la liste des actions via l'environnement Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rendu(solutions_list):\n",
    "    \"\"\" affiche la plus courte sequence d'actions permettant d'atteindre l'objectif q partir des solutions fournies\n",
    "    Parameters\n",
    "    ----------\n",
    "    solutions_list : liste des solutions trouvees\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    mini_sol = solutions_list[0]\n",
    "    for s in  solutions_list:\n",
    "        if len(s[2]) < len(mini_sol[2]): mini_sol = s\n",
    "    print(\"une solution en \", len(mini_sol[2]), \" etapes : \")\n",
    "    env.reset()\n",
    "    env.render()\n",
    "    for i in range(0, len(mini_sol[2])):\n",
    "        env.env.s = mini_sol[2][i]\n",
    "        print(\"action \", actions[mini_sol[3][i]])\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aucune solution trouvee !!\n"
     ]
    }
   ],
   "source": [
    "##ON LANCE LA RESOLUTION : \n",
    "solutions = try_qlearn(1000, 50)\n",
    "if(len(solutions)>0):rendu(solutions)\n",
    "#relancer le bloc si pas de solution trouvee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_frequence_sol(solutions_list):\n",
    "    \"\"\"\n",
    "    dessine la frequence de solution trouvees\n",
    "    Parameters\n",
    "    ----------\n",
    "    solutions : liste des solutions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    xs = [x[0] for x in solutions_list]\n",
    "    ys = [y[1] for y in solutions_list]\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(xs, ys, '.')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_frequence_sol(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Q, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <font color=\"red\">Test de résolution en mode non déterministe</font>\n",
    "Rechargeons l'environnement en mode \"glissant\".\n",
    "\n",
    "Il suffit de réinitialiser la table Q et de lancer l'algorithme...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "une solution en  16  etapes : \n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "S\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFF\u001b[41mF\u001b[0mF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Gauche\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFH\u001b[41mF\u001b[0m\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF\u001b[41mG\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('FrozenLake8x8-v1', is_slippery=True)\n",
    "\n",
    "env.reset()\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "lambda_learn = .3\n",
    "gamma = 0.99\n",
    "epsilon = 1.\n",
    "nb_episodes = 5000\n",
    "##ON LANCE LA RESOLUTION : \n",
    "solutions = try_qlearn()\n",
    "if(len(solutions)>0):rendu(solutions)\n",
    "plot_frequence_sol(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.17959011e-10, 4.96923458e-09, 2.03654356e-10, 1.31297306e-12],\n",
       "       [5.00571022e-10, 6.78747858e-10, 7.69671503e-09, 3.67940180e-09],\n",
       "       [2.25531086e-11, 3.34981685e-07, 1.50603786e-09, 2.67239193e-11],\n",
       "       [2.20775018e-09, 2.98997409e-10, 8.60384131e-07, 3.24809261e-10],\n",
       "       [1.06428067e-09, 1.14894021e-07, 1.43884533e-06, 1.20986540e-09],\n",
       "       [2.62482891e-06, 1.87506123e-06, 3.37641080e-09, 1.02896525e-07],\n",
       "       [3.18058509e-07, 2.45325681e-08, 5.19759455e-06, 1.77693455e-08],\n",
       "       [3.22837020e-08, 8.52871391e-07, 3.81255717e-08, 5.31397399e-07],\n",
       "       [6.38662236e-11, 9.36102756e-12, 7.42628040e-11, 3.81615157e-09],\n",
       "       [5.69618211e-10, 2.23892608e-08, 1.11010365e-10, 6.01168563e-10],\n",
       "       [2.60087144e-09, 1.86999878e-08, 1.39278344e-11, 1.26489316e-07],\n",
       "       [1.82694277e-10, 2.05669773e-08, 2.25024147e-10, 4.93605903e-07],\n",
       "       [9.05001636e-08, 1.81897486e-06, 1.67126646e-08, 2.39687735e-09],\n",
       "       [3.02583381e-07, 5.24413423e-06, 1.15302832e-08, 4.83830098e-08],\n",
       "       [3.42153156e-08, 3.94957847e-07, 2.17380920e-05, 4.85620867e-08],\n",
       "       [4.31460383e-06, 3.15275544e-06, 8.95149946e-08, 4.46338180e-07],\n",
       "       [1.48719464e-11, 2.98729924e-12, 8.36630595e-10, 3.00650004e-12],\n",
       "       [1.99920451e-10, 3.62389220e-11, 9.62573185e-11, 2.64004908e-10],\n",
       "       [4.01534122e-08, 1.00556311e-10, 6.25214692e-12, 3.79921661e-12],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [6.39056238e-08, 2.57986307e-09, 9.02634378e-07, 2.24166945e-07],\n",
       "       [4.02619823e-09, 1.28873211e-09, 7.15808269e-06, 1.08515735e-06],\n",
       "       [5.66621356e-08, 4.60386450e-07, 3.09593440e-05, 4.73647298e-07],\n",
       "       [9.84905135e-07, 3.05907827e-05, 9.17515130e-07, 1.37457305e-07],\n",
       "       [2.71336954e-12, 3.25117188e-12, 2.96356719e-10, 2.63648615e-12],\n",
       "       [9.08678145e-12, 8.14325156e-12, 2.84991992e-10, 8.35573826e-12],\n",
       "       [1.59555790e-11, 2.02328110e-10, 1.34197160e-11, 2.85614842e-08],\n",
       "       [3.05569914e-11, 2.07212062e-08, 3.72204971e-11, 8.40564301e-11],\n",
       "       [1.78252229e-07, 1.98602198e-09, 1.65857586e-09, 1.06260336e-08],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.79493357e-07, 8.80581204e-06, 1.71410881e-05, 3.13104957e-07],\n",
       "       [4.13031990e-05, 3.09111540e-05, 2.23895996e-06, 7.53161499e-07],\n",
       "       [6.78394444e-13, 8.92904195e-13, 6.59964149e-11, 1.63166446e-12],\n",
       "       [5.75026707e-13, 2.45677245e-12, 7.15726631e-13, 7.46494080e-11],\n",
       "       [1.03139739e-12, 4.57189861e-14, 2.67646676e-13, 1.43462062e-10],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.11420256e-09, 9.00621076e-09, 1.87929377e-06, 1.77749637e-08],\n",
       "       [7.07751014e-08, 7.25484886e-08, 1.94141708e-08, 5.94214316e-06],\n",
       "       [3.13863879e-07, 1.69856070e-06, 6.53546204e-06, 2.37135339e-05],\n",
       "       [3.34046975e-05, 6.10154893e-04, 7.88835625e-05, 2.95033132e-05],\n",
       "       [5.39369722e-14, 5.41232763e-14, 4.99601746e-13, 5.64658446e-14],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.68265049e-09],\n",
       "       [0.00000000e+00, 2.47953095e-08, 0.00000000e+00, 6.84706148e-07],\n",
       "       [7.80091740e-08, 0.00000000e+00, 6.87133754e-08, 7.64693929e-08],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.36471323e-04, 1.79098646e-05, 2.39828274e-03, 4.03806262e-03],\n",
       "       [1.68186907e-14, 2.03082432e-14, 1.19970972e-14, 8.51226901e-15],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.72421986e-08],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.34672737e-04, 1.30069493e-03, 3.53408312e-01, 9.73579508e-02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.09488154e-14],\n",
       "       [6.44855199e-15, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.00000000e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus on relance les tests, plus on a de chance de trouver une solution..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Double Q Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codez maintenant l'algorithme de double Q-Learning et comparez les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
