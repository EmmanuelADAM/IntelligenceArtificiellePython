{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/GymFrozenLakeQLearning-Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## Appliqué à [Gym.OpenAI](https://gym.openai.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test de ML par Q-Learning pour atteindre l'objectif\n",
    "\n",
    "**Utilisation de l'environnement Gym**\n",
    " (voir la page d'introduction à [Gym](https://gym.openai.com))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Si besoin, importer gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "#### L'environnement FrozenLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- Utiliser l'environnement `FrozenLake8x8-v1` (un labyrinthe en mode texte)\n",
    "  - **ATTENTION**, avec d'ancienne version de gym (sous colab, ...), il faut utiliser la version 0 (`FrozenLake8x8-v0`)- 4 actions sont possibles (Left(0), Down(1), Right(2), Up(3))\n",
    "  - l'adjectif \"Frozen\" signifie qu'une *action n'est pas déterministe !*\n",
    "    - à partir d'une case \"gelée\", aller à droite peut .. mener à droite, ou pas\n",
    "    - => intérêt du Q-Learning adapté à ce type d'environnement probabiliste\n",
    "- Le labyrinthe est ainsi composé de zones glacées, de puits, et d'un objectif\n",
    "\n",
    "\n",
    "**N.B.** \n",
    "  - *Cet environnement fonctionne bien sous colab, jupyterlab.. quelques soucis de l'affichage de l'état courant (carré rouge) sous Pyzo....* \n",
    "  - Il est fortement conseillé de débuter avec un environnement déterministe pour évaluer la bonne marche de l'algo de Q-Learning que vous aurez développer.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Etude de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specification de l'environnement :  EnvSpec(FrozenLake-v1)\n",
      "espace d'actions :  Discrete(4)  => 4 actions \"discretes\" (non continues)\n",
      "espace d'etats :  Discrete(16)  => 16 etats distincts\n",
      "Environnement et etat initial (en rouge) : \n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "S = Start (pos 0), G = Goal (pos 15), H = Hole, F = Frozen place\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=False) # tester FrozenLake8x8 pour l'environnement plus large\n",
    "print(\"specification de l'environnement : \", env.spec)\n",
    "print(\"espace d'actions : \", env.action_space , \" => 4 actions \\\"discretes\\\" (non continues)\") #ici 4 actions discrétisée\n",
    "print(\"espace d'etats : \", env.observation_space , \" => 16 etats distincts\") #ici 4x4 cellules possibles\n",
    "\n",
    "env.reset()\n",
    "print(\"Environnement et etat initial (en rouge) : \")\n",
    "env.render()\n",
    "print(\"S = Start (pos 0), G = Goal (pos 15), H = Hole, F = Frozen place\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Test des actions\n",
    "\n",
    "Sous Gym, `step` permet d'effectuer une action. \n",
    "En retour la fonction retourne une observation sur l'etat d'arrivee, sa recompense, son type (final ou non), et des informations.\n",
    "Ici, dans FrozenLake, \n",
    "- observation = position où se trouve l'agent\n",
    "- reward = recompense\n",
    "- done = vrai si but atteint\n",
    "- info = probabilité de succès de l'action \n",
    "  - en mode déterministe, sol non glissant, la proba de réussite est de 100%\n",
    "  - en mode non déterministe, sol glissant, la proba de réussite est de 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 0 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "###### Test des actions\n",
    "env.reset()\n",
    "action = 0\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 4 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = 1\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 1 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = 2\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 0 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = 3\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Cas non déterministe**\n",
    "\n",
    "L'environnement FrozenLake peut également être chargé en mode non déterministe : chaque état est une case gelée, et chaque action qui s'y deroule n'a qu'une chance sur trois de réussir !\n",
    "\n",
    "Chargeons l'environnement dans ce mode et testons les actions à partir de l'état initial : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 5 ,gain: 0 ,fini: True , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=True) \n",
    "\n",
    "env.reset()\n",
    "env.env.s = 5\n",
    "action = 0\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 5 ,gain: 0 ,fini: True , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.env.s = 5\n",
    "action = 1\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 5 ,gain: 0 ,fini: True , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.env.s = 5\n",
    "action = 2\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Up)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 5 ,gain: 0 ,fini: True , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.env.s = 5\n",
    "action = 3\n",
    "observation, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On est clairement ici dans un environnement non déterministe (une même action à partir d'un même état ne mène pas toujours au même résultat); c'est le contexte de prédilection de l'algo de Q-Learning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <font color=\"red\">Premiere résolution en mode déterministe</font>\n",
    "Important, pour valider l'apprentissage de votre algorithme avant de passer en mode non-déterministe, il vaut mieux le tester sur un environnement où chaque action à 100% de réussite. Ci-dessous un exemple sur le mini labyrinthe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 1 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 2 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "FH\u001b[41mF\u001b[0mH\n",
      "FFFH\n",
      "HFFG\n",
      "pos° actuelle: 6 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "pos° actuelle: 10 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "pos° actuelle: 14 ,gain: 0.0 ,fini: False , {'prob': 1.0}\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "pos° actuelle: 15 ,gain: 1.0 ,fini: True , {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "env.reset()\n",
    "actions = [2,2,1,1,1,2]\n",
    "for a in actions:\n",
    "    observation, reward, done, info = env.step(a)\n",
    "    env.render()\n",
    "    print(\"pos° actuelle:\", observation,\",gain:\", reward,\",fini:\", done,\",\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exemple d'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "env = gym.make('FrozenLake8x8-v1', is_slippery=False)\n",
    "actions = {0:'Gauche', 1:'Bas', 2:'Droite', 3:'Haut'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialiser la Q-Table\n",
    "# autant de cases que l'environnement en possède, \n",
    "# contenant autant de valeurs que d'actions possibles\n",
    "# donc ici une matrice 64 x 4\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place des paramètres\n",
    "Pour rappel l'algo de Q Learning simple repose sur cette équation : \n",
    "$Q(s,a) \\gets \\lambda \\times (r + \\gamma \\times max_{a'}(Q(s', a'))) + (1-\\lambda ) \\times Q(s,a)$ avec \n",
    "  - $\\lambda$ : coef d'apprentissage\n",
    "  - $\\gamma$ : coef de réduction \n",
    "  - $r$ : récompense\n",
    "  \n",
    "Cette équation donne la qualité de l'action *a* à partir de l'état *s*.\n",
    "\n",
    "Initialement, les actions sont choisies aléatoirement et notées; puis au fil des tests les actions les plus valuées sont choisies. Pour cela, un tirage est effectuée, s'il est inférieur à un $\\epsilon$, le choix est aléatoire. Cet $\\epsilon$ décroit au fil des tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_learn = .1\n",
    "gamma = 0.99\n",
    "epsilon = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupérer la meilleure action\n",
    "`argmax(tab)` retourne l'indice de la plus grande valeur du tableau.\n",
    "\n",
    "`argmax(Q[2])` retourne donc le no de l'action la plus intéressante à partir de l'état 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'algorithme de Q-Learning simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##algorithme de Q-Learning simple\n",
    "def q_learn(nb_actions):\n",
    "    \"\"\"\n",
    "    effectue un cycle d'apprentissage/recherche de solution' via le Q-Learning simple\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : no de l'etape\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    total_r : recompense totale\n",
    "    r : recompense du dernier etat rencontre\n",
    "    states_list : liste des etats traverses\n",
    "    actions_list : liste des actions effectuees\n",
    "\n",
    "    \"\"\"\n",
    "    s = env.reset()\n",
    "    total_r = 0\n",
    "    done = False\n",
    "    step = 0\n",
    "    states_list = []\n",
    "    actions_list = []\n",
    "    # The Q-Table learning algorithm\n",
    "    while not done and step < nb_actions:\n",
    "        step += 1\n",
    "        actions = Q[s, :]\n",
    "        # Choose random action if initial step or if there is no interesting action\n",
    "        if rnd.random()<epsilon or np.max(actions)==0:\n",
    "            # explore\n",
    "            a = rnd.randint(0, env.action_space.n-1)\n",
    "        else:\n",
    "            # enforce\n",
    "            a = np.argmax(actions)\n",
    "\n",
    "        # Get new state and reward from environment\n",
    "        new_state, r, done, _ = env.step(a)\n",
    "\n",
    "        # Q-Learning\n",
    "        Q[s, a] = Q[s, a] + lambda_learn*(r + gamma * np.max(Q[new_state, :]) - Q[s, a])\n",
    "        s = new_state\n",
    "        total_r = total_r + r\n",
    "        states_list.append(s)\n",
    "        actions_list.append(a)\n",
    "    return total_r, r, states_list, actions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_qlearn(nb_episodes = 4000, nb_actions = 64):\n",
    "    \"\"\"\n",
    "    lance nb_episodes fois un cycle de Q-Learning et memorise chaque solution trouvee\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    solutions_list : liste des solutions (no, recompense totale, liste des etats, liste des actions)\n",
    "    \"\"\"\n",
    "    global epsilon\n",
    "    states_list = []\n",
    "    actions_list = []\n",
    "    solutions_list = []\n",
    "    epsilon = 1\n",
    "    for i in range(nb_episodes):\n",
    "        # Reset environment and get first new observation\n",
    "        total_r, r, states_list, actions_list = q_learn(nb_actions)\n",
    "        epsilon = epsilon * 0.999\n",
    "        # memorize if a solution has been found\n",
    "        if r == 1: solutions_list.append((i, total_r, states_list, actions_list))\n",
    "        \n",
    "    if(len(solutions_list) == 0): print(\"aucune solution trouvee !!\")\n",
    "\n",
    "    return solutions_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage de du résultat\n",
    "Affichons maintenant la liste des actions via l'environnement Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rendu(solutions_list):\n",
    "    \"\"\" affiche la plus courte sequence d'actions permettant d'atteindre l'objectif q partir des solutions fournies\n",
    "    Parameters\n",
    "    ----------\n",
    "    solutions_list : liste des solutions trouvees\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    mini_sol = solutions_list[0]\n",
    "    for s in  solutions_list:\n",
    "        if len(s[2]) < len(mini_sol[2]): mini_sol = s\n",
    "    print(\"une solution en \", len(mini_sol[2]), \" etapes : \")\n",
    "    env.reset()\n",
    "    env.render()\n",
    "    for i in range(0, len(mini_sol[2])):\n",
    "        env.env.s = mini_sol[2][i]\n",
    "        print(\"action \", actions[mini_sol[3][i]])\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "une solution en  14  etapes : \n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "S\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHF\u001b[41mF\u001b[0mFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFF\u001b[41mF\u001b[0mF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFH\u001b[41mF\u001b[0m\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF\u001b[41mG\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "##ON LANCE LA RESOLUTION : \n",
    "solutions = try_qlearn(3000, 50)\n",
    "if(len(solutions)>0):rendu(solutions)\n",
    "#relancer le bloc si pas de solution trouvee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_frequence_sol(solutions_list):\n",
    "    \"\"\"\n",
    "    dessine la frequence de solution trouvees\n",
    "    Parameters\n",
    "    ----------\n",
    "    solutions : liste des solutions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    xs = [x[0] for x in solutions_list]\n",
    "    ys = [y[1] for y in solutions_list]\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(xs, ys, '.')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_frequence_sol(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87, 0.86, 0.88, 0.87],\n",
       "       [0.87, 0.87, 0.89, 0.87],\n",
       "       [0.88, 0.87, 0.9 , 0.89],\n",
       "       [0.89, 0.9 , 0.9 , 0.89],\n",
       "       [0.89, 0.91, 0.91, 0.9 ],\n",
       "       [0.38, 0.92, 0.14, 0.34],\n",
       "       [0.48, 0.  , 0.07, 0.  ],\n",
       "       [0.  , 0.47, 0.03, 0.  ],\n",
       "       [0.3 , 0.01, 0.24, 0.87],\n",
       "       [0.38, 0.  , 0.15, 0.88],\n",
       "       [0.15, 0.  , 0.36, 0.89],\n",
       "       [0.09, 0.  , 0.91, 0.51],\n",
       "       [0.9 , 0.92, 0.92, 0.9 ],\n",
       "       [0.91, 0.93, 0.91, 0.91],\n",
       "       [0.92, 0.32, 0.41, 0.01],\n",
       "       [0.32, 0.95, 0.31, 0.09],\n",
       "       [0.  , 0.  , 0.  , 0.16],\n",
       "       [0.  , 0.  , 0.  , 0.09],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.11, 0.93, 0.55],\n",
       "       [0.92, 0.  , 0.94, 0.92],\n",
       "       [0.93, 0.93, 0.95, 0.91],\n",
       "       [0.94, 0.96, 0.95, 0.94],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.03, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.43],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.67, 0.38, 0.94],\n",
       "       [0.93, 0.97, 0.96, 0.95],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.29, 0.  ],\n",
       "       [0.04, 0.  , 0.97, 0.44],\n",
       "       [0.96, 0.98, 0.97, 0.96],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.99, 0.98, 0.97],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.99, 0.98],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Q, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <font color=\"red\">Test de résolution en mode non déterministe</font>\n",
    "Rechargeons l'environnement en mode \"glissant\".\n",
    "\n",
    "Il suffit de réinitialiser la table Q et de lancer l'algorithme...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "une solution en  24  etapes : \n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Haut\n",
      "\n",
      "S\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Haut\n",
      "\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Haut\n",
      "\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Haut\n",
      "\n",
      "SFFFFFFF\n",
      "FFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Haut\n",
      "\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Haut\n",
      "\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Gauche\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Haut\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFF\u001b[41mF\u001b[0mF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFF\u001b[41mF\u001b[0mF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Bas\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFF\u001b[41mF\u001b[0mF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFH\u001b[41mF\u001b[0mF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFF\u001b[41mF\u001b[0mF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Haut\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFH\u001b[41mF\u001b[0m\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFH\u001b[41mF\u001b[0m\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "action  Droite\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF\u001b[41mG\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('FrozenLake8x8-v1', is_slippery=True)\n",
    "\n",
    "env.reset()\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "lambda_learn = .8\n",
    "gamma = 0.99\n",
    "epsilon = 1.\n",
    "nb_episodes = 5000\n",
    "##ON LANCE LA RESOLUTION : \n",
    "solutions = try_qlearn()\n",
    "if(len(solutions)>0):rendu(solutions)\n",
    "plot_frequence_sol(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus on relance les tests, plus on a de chance de trouver une solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37, 0.37, 0.36, 0.38],\n",
       "       [0.37, 0.45, 0.37, 0.37],\n",
       "       [0.38, 0.49, 0.38, 0.38],\n",
       "       [0.38, 0.4 , 0.54, 0.42],\n",
       "       [0.47, 0.32, 0.51, 0.51],\n",
       "       [0.51, 0.42, 0.47, 0.49],\n",
       "       [0.61, 0.49, 0.62, 0.42],\n",
       "       [0.53, 0.67, 0.53, 0.52],\n",
       "       [0.36, 0.19, 0.21, 0.36],\n",
       "       [0.36, 0.35, 0.26, 0.39],\n",
       "       [0.19, 0.19, 0.32, 0.47],\n",
       "       [0.33, 0.02, 0.38, 0.54],\n",
       "       [0.26, 0.38, 0.36, 0.52],\n",
       "       [0.33, 0.38, 0.19, 0.54],\n",
       "       [0.5 , 0.5 , 0.35, 0.53],\n",
       "       [0.67, 0.53, 0.66, 0.6 ],\n",
       "       [0.14, 0.14, 0.36, 0.15],\n",
       "       [0.3 , 0.11, 0.11, 0.11],\n",
       "       [0.32, 0.07, 0.01, 0.03],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.01, 0.  , 0.47, 0.  ],\n",
       "       [0.08, 0.09, 0.11, 0.54],\n",
       "       [0.48, 0.22, 0.22, 0.17],\n",
       "       [0.59, 0.54, 0.78, 0.55],\n",
       "       [0.12, 0.11, 0.18, 0.11],\n",
       "       [0.06, 0.06, 0.04, 0.05],\n",
       "       [0.03, 0.01, 0.01, 0.02],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.06, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.11, 0.1 , 0.65, 0.12],\n",
       "       [0.62, 0.67, 0.84, 0.53],\n",
       "       [0.11, 0.1 , 0.13, 0.06],\n",
       "       [0.05, 0.1 , 0.  , 0.01],\n",
       "       [0.  , 0.  , 0.  , 0.04],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.02, 0.  ],\n",
       "       [0.01, 0.01, 0.  , 0.  ],\n",
       "       [0.02, 0.03, 0.02, 0.87],\n",
       "       [0.37, 0.35, 0.89, 0.77],\n",
       "       [0.1 , 0.04, 0.02, 0.04],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.01, 0.  ],\n",
       "       [0.01, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.19, 0.17, 0.96, 0.17],\n",
       "       [0.1 , 0.01, 0.02, 0.05],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.04, 0.78, 0.99, 0.18],\n",
       "       [0.1 , 0.08, 0.04, 0.1 ],\n",
       "       [0.02, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Q, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
