{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/introHuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace : des modèles entraînés\n",
    "\n",
    "[HuggingFace](https://huggingface.co/) est un site recueillant les modèles IA entraînés, les plus connus (GPT, Bart, Mistral...) comme des plus modestes.\n",
    "Ce site met aussi à disposition des dataset (comme le site kaggle).\n",
    "\n",
    "Un modèle comprend plusieurs éléments. Par exemple, pour le texte, il contiendra un vocabulaire, l'outil de \"tokenisation\", un réseau entraîné, et un outil de restitution du résultat.\n",
    "\n",
    " \n",
    "Les modèles peuvent être téléchargés en local (attention à la taille de certains), ou utilisés en ligne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Transformers\n",
    "Les transformers sont utilisés pour convertir une entrée (texte par exemple) en entrée assimilable par un ensemble d'outils contenant un réseau de neurones.\n",
    "\n",
    "Il est nécessaire de les télécharger comme une librairie classique : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#téléchargement, un peu long parfois, de la librairie transformers\n",
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation en mémoire\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## pipeline\n",
    "Un pipeline est une suite d'outils (tokenizer, analyseur, ...) visant un but précis.\n",
    "\n",
    "Par exemple, le pipeline suivant analyse le \"sentiment\" d'un texte : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement du \"detecteur de sentiments\" par défaut\n",
    "#la première utilisation prend un peu de temps de téléchargement\n",
    "detecteur_de_sentiments = pipeline(\"sentiment-analysis\")\n",
    "#chargement du \"detecteur de sentiments\"  cardiffnlp\n",
    "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classement par defaut = \n",
      "I like discover new thing in my courses at UPHF.\n",
      "\t classifier par defaut :  {'label': 'POSITIVE', 'score': 0.9983413219451904}\n",
      "\t classifier cardiff :  {'label': 'positive', 'score': 0.9546298980712891}\n",
      "But I hate writing my practical work reports !\n",
      "\t classifier par defaut :  {'label': 'NEGATIVE', 'score': 0.9973371624946594}\n",
      "\t classifier cardiff :  {'label': 'negative', 'score': 0.9157376289367676}\n",
      "I should better sleep at night rather than in the courses\n",
      "\t classifier par defaut :  {'label': 'NEGATIVE', 'score': 0.9995858073234558}\n",
      "\t classifier cardiff :  {'label': 'neutral', 'score': 0.5100991129875183}\n"
     ]
    }
   ],
   "source": [
    "phrases =     [\n",
    "        \"I like discover new thing in my courses at UPHF.\",\n",
    "        \"But I hate writing my practical work reports !\", \n",
    "        \"I should better sleep at night rather than in the courses\"\n",
    "    ]\n",
    "\n",
    "default_output = detecteur_de_sentiments(phrases)\n",
    "cardiff_output =pipe(phrases)\n",
    "print(\"classement par defaut = \")\n",
    "for i in range(len(phrases)):\n",
    "    print(phrases[i])\n",
    "    print(\"\\t classifier par defaut : \", default_output[i])\n",
    "    print(\"\\t classifier cardiff : \", cardiff_output[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Choix du modèle\n",
    "Sur huggingFace, il est assez simple de choisir son modèle : \n",
    "  - cliquez en haut au centre sur **Models**\n",
    "  - choisissez dans **Natural Language Processing** le traitement désiré (par exemple TextClassification)\n",
    "  - choisissez ensuite le modèle voulu, ou plus téléchargé, ou le plus \"liké\"\n",
    "  - cliquez sur **</> use in transformers**\n",
    "  - vous obtenez ainsi le code pour charger le pipeline (pour ce TP, on choisira \"Use a pipeline as a high-level helper\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Travail à faire\n",
    "\n",
    "Peu de code dans ce TP. \n",
    "\n",
    "1. **Classement** : Reprenez le dataset sur le classement de livres et tester 3 modèles (dont au moins un basé sur le français) sur les 50 premières données du dataset. Comparez les résultats.\n",
    "\n",
    "2. **Résumé automatique** : prenez le dataset [samsun](https://huggingface.co/datasets/samsum) et testez  3 modèles de résumé sur les 20 premières  lignes du dataset. Evaluez par vous même la qualité des résumés.\n",
    "\n",
    "3. **Génération de texte**. Chargez trois modèles générateurs de texte et demandez la recette des panckakes et évaluez les réponses.  \n",
    "Commencez la recette : ``sentences = generator(\"To make pancakes, I need flour\", max_length=30, num_return_sequences=5,  return_full_text=True)``   \n",
    "(ceci demande la suite du texte, 5 fois, avec des réponses de 30 mots max).\n",
    "\n",
    "4. **Réponse à tout** : utilisez 3 modèles de question-answering et posez 3 questions sur le texte anglais de votre choix. Comparez.\n",
    "\n",
    "**A rendre**, les codes, les questions et réponses. Ainsi votre réflexion sur la confiance envers les modèles existants. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exemple d'utilisation de \"question-answering\"\n",
    "pipe = pipeline(\"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from when comes artificial intelligence ?  -  {'score': 0.07508504390716553, 'start': 119, 'end': 123, 'answer': '1956'}\n",
      "what is the concept behind artificial intelligence ?  -  {'score': 0.7541843056678772, 'start': 533, 'end': 546, 'answer': 'automated art'}\n"
     ]
    }
   ],
   "source": [
    "context = \"The academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[20] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[21] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[22][23] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet's automaton created in the early 1800s.[24]\"\n",
    "\n",
    "question = \"from when comes artificial intelligence ?\"\n",
    "output = pipe({\"context\": context, \"question\": question })\n",
    "print(question, \" - \", output)\n",
    "question = \"what is the concept behind artificial intelligence ?\"\n",
    "output = pipe({\"context\": context, \"question\": question })\n",
    "print(question, \" - \", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
