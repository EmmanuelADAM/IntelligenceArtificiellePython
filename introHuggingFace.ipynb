{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/introHuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace : des modèles entraînés\n",
    "\n",
    "[HuggingFace](https://huggingface.co/) est un site recueillant les modèles IA entraînés, les plus connus (GPT, Bart, Mistral...) comme des plus modestes.\n",
    "Ce site met aussi à disposition des dataset (comme le site kaggle).\n",
    "\n",
    "Un modèle comprend plusieurs éléments. Par exemple, pour le texte, il contiendra un vocabulaire, l'outil de \"tokenisation\", un réseau entraîné, et un outil de restitution du résultat.\n",
    "\n",
    " \n",
    "Les modèles peuvent être téléchargés en local (attention à la taille de certains), ou utilisés en ligne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Transformers\n",
    "Les transformers sont utilisés pour convertir une entrée (texte par exemple) en entrée assimilable par un ensemble d'outils contenant un réseau de neurones.\n",
    "\n",
    "Il est nécessaire de les télécharger comme une librairie classique : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#téléchargement, un peu long parfois, de la librairie transformers\n",
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation en mémoire\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## pipeline\n",
    "Un pipeline est une suite d'outils (tokenizer, analyseur, ...) visant un but précis.\n",
    "\n",
    "Par exemple, le pipeline suivant analyse le \"sentiment\" d'un texte : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmanuel adam\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement du \"detecteur de sentiments\" par défaut\n",
    "#la première utilisation prend un peu de temps de téléchargement\n",
    "detecteur_de_sentiments = pipeline(\"sentiment-analysis\")\n",
    "#chargement du \"detecteur de sentiments\"  cardiffnlp\n",
    "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:403: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classement par defaut = \n",
      "I like discover new thing in my courses at UPHF.\n",
      "\t classifier par defaut :  {'label': 'POSITIVE', 'score': 0.9983413219451904}\n",
      "\t classifier cardiff :  {'label': 'positive', 'score': 0.9546298980712891}\n",
      "But I hate writing my practical work reports !\n",
      "\t classifier par defaut :  {'label': 'NEGATIVE', 'score': 0.9973371624946594}\n",
      "\t classifier cardiff :  {'label': 'negative', 'score': 0.9157376289367676}\n",
      "I should better sleep at night rather than in the courses\n",
      "\t classifier par defaut :  {'label': 'NEGATIVE', 'score': 0.9995858073234558}\n",
      "\t classifier cardiff :  {'label': 'neutral', 'score': 0.5100991129875183}\n"
     ]
    }
   ],
   "source": [
    "phrases =     [\n",
    "        \"I like discover new thing in my courses at UPHF.\",\n",
    "        \"But I hate writing my practical work reports !\", \n",
    "        \"I should better sleep at night rather than in the courses\"\n",
    "    ]\n",
    "\n",
    "default_output = detecteur_de_sentiments(phrases)\n",
    "cardiff_output =pipe(phrases)\n",
    "print(\"classement par defaut = \")\n",
    "for i in range(len(phrases)):\n",
    "    print(phrases[i])\n",
    "    print(\"\\t classifier par defaut : \", default_output[i])\n",
    "    print(\"\\t classifier cardiff : \", cardiff_output[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Choix du modèle\n",
    "Sur huggingFace, il est assez simple de choisir son modèle : \n",
    "  - cliquez en haut au centre sur **Models**\n",
    "  - choisissez dans **Natural Language Processing** le traitement désiré (par exemple TextClassification)\n",
    "  - choisissez ensuite le modèle voulu, ou plus téléchargé, ou le plus \"liké\"\n",
    "  - cliquez sur **</> use in transformers**\n",
    "  - vous obtenez ainsi le code pour charger le pipeline (pour ce TP, on choisira \"Use a pipeline as a high-level helper\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Travail à faire\n",
    "\n",
    "Peu de code dans ce TP. \n",
    "\n",
    "1. **Classement** : Prenez le dataset sur le [classement de livres](https://huggingface.co/datasets/Abirate/french_book_reviews) et tester 3 modèles (dont au moins un basé sur le français) sur les 50 premières données du dataset. Comparez les résultats.\n",
    "\n",
    "2. **Résumé automatique** : Prenez le dataset [these abstracts](https://huggingface.co/datasets/jgammack/THESES-abstracts) et testez  3 modèles de résumé sur les 10 premières  lignes du dataset. Evaluez par vous même la qualité des résumés par rapport au titre de la thèse.\n",
    "\n",
    "3. **Génération de texte**. Chargez trois modèles générateurs de texte et demandez la recette des panckakes et évaluez les réponses.  \n",
    "Commencez la recette : ``sentences = generator(\"To make pancakes, I need flour\", max_length=30, num_return_sequences=5,  return_full_text=True)``   \n",
    "(ceci demande la suite du texte, 5 fois, avec des réponses de 30 mots max).\n",
    "\n",
    "4. **Réponse à tout** : Utilisez 3 modèles de *question-answering* et posez 3 questions sur 3 textes anglais de votre choix (parmi les abstracts des theses). Comparez.\n",
    "\n",
    "5. **Réponse à tout 2** : Utilisez maintenant des modèles de type *text2text-generation* pour ces même questions sur ces mêmes textes. Comparez les modèles.\n",
    "\n",
    "6. **Traduction** : Utilisez maintenant des modèles de type *translation* pour traduire ces textes en français, et une autre langue de votre choix. Comparez les modèles.\n",
    "\n",
    "\n",
    "**A rendre**, les codes, les questions et réponses. Ainsi votre réflexion sur la confiance envers les modèles existants. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Note python : Pour lire un fichier CSV\n",
    "La librairie pandas est recommandée. Voici des exemples d'utilisation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pda\n",
    "filename = \"REPERTOIRE/VOTRE_FICHIER.CSV\"\n",
    "#chargement d'un fichier CSV, donnée séparées par des virgules, encodage en UTF-8\n",
    "df = pda.read_csv(filename)\n",
    "\n",
    "#chargement d'un fichier CSV, donnée séparées par des tabulations, encodage en ISO-8859-1\n",
    "#df = pda.read_csv(filename, sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération des valeurs d'une colonne dans un tableau : \n",
    "textes = df['reader_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir de hugging face, regardez la doc du dataset \"Use this dataset\" et choisissez la libairie de votre choix. \n",
    "# Ex avec Pandas : \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"hf://datasets/Abirate/french_book_reviews/french_books_reviews.jsonl\", lines=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Question-answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exemple d'utilisation de \"question-answering\"\n",
    "pipe = pipeline(\"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from when comes artificial intelligence ?  -  {'score': 0.07508504390716553, 'start': 119, 'end': 123, 'answer': '1956'}\n",
      "what is the concept behind artificial intelligence ?  -  {'score': 0.7541843056678772, 'start': 533, 'end': 546, 'answer': 'automated art'}\n"
     ]
    }
   ],
   "source": [
    "context = \"The academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[20] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[21] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[22][23] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet's automaton created in the early 1800s.[24]\"\n",
    "\n",
    "question = \"from when comes artificial intelligence ?\"\n",
    "output = pipe({\"context\": context, \"question\": question })\n",
    "print(question, \" - \", output)\n",
    "question = \"what is the concept behind artificial intelligence ?\"\n",
    "output = pipe({\"context\": context, \"question\": question })\n",
    "print(question, \" - \", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
