{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/TPMLGymGA-CarttPole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## Appliqué à [Gym.OpenAI]((https://gym.openai.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir la page d'[introduction à Gym](https://github.com/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/TPMLIntroGym.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation de gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outil AUTRE QUE COLAB (pyzo, jupyter lab, .....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>Sous colab</font>\n",
    "*Sous colab, l'affichage ne sera pas dynamique.. Il faudra passer soit par un rendu sous forme de plot (matplotlib), soit passer par une vidéo à enregistrer...*\n",
    "\n",
    "***Solution pour affichage statique***<br>\n",
    "*Il vous faut importer, seulement si vous utilisez colab, les packages suivants :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "!apt-get install x11-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Charger l' environnement\n",
    "On utilise ici l'environnement `CartPole-v1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Les valeurs des caractéristiques\n",
    "Pour `CartPole-v1`, vous trouverez l'explication des valeurs [ici](https://www.gymlibrary.ml/pages/environments/classic_control/cart_pole).\n",
    "\n",
    "**Actions**\n",
    "\n",
    "| Valeur | Action | \n",
    "|:--:|:--:|\n",
    "| 0 | aller à gauche | \n",
    "| 1 | aller à droite | \n",
    "\n",
    "\n",
    "**Observations**\n",
    "\n",
    "| No | Observation | Min | Max |\n",
    "|:--:|:--:|:--:|:--:|\n",
    "| 0 | Position | -4.8 | 4.8 |\n",
    "| 1 | Velocité | -inf | +inf |\n",
    "| 2 | Angle du mat (radian) | -0.418 | +0.418 |\n",
    "| 3 | Velocité anglulaire du mat | -inf | +inf |\n",
    "\n",
    "Vérification : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvSpec(CartPole-v1)\n",
      "nombre et type d'actions =  Discrete(2)\n",
      "nombre et type d'observations =  Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "valeurs de  observations les plus basses =  [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "valeurs de observations les plus elevées =  [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.spec)\n",
    "print(\"nombre et type d'actions = \", env.action_space) \n",
    "print(\"nombre et type d'observations = \", env.observation_space) \n",
    "print(\"valeurs de  observations les plus basses = \", env.observation_space.low) \n",
    "print(\"valeurs de observations les plus elevées = \", env.observation_space.high) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Re)Initialiser l'environnement\n",
    "`env.reset()` initialise les variables d'environnement. L'exécution est obligatoire après avoir chargé l'environnement. Ici ce sont la position de départ et la vitesse.\n",
    "Pour avoir un environnement non déterministe, par défaut `env.reset()` affecte des valeurs entre  -0.05 et +0.05 pour chaque champs observable : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02057121,  0.02878238, -0.03504172,  0.02839395], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais ici nous souhaitons partir du même point (0) à vitesse nulle, mais avec un angle en radian du mat de 0.1 rad (mat penché légèrement à droite) à chaque test d'une séquence d'actions. Avant chaque évaluation de séquence d'actions, ***on n'utilisera pas*** `env.reset()` par la suite et on écrira donc : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.state= np.array([0., 0., 0.1, 0.])\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Les actions\n",
    "- Dans `CartPole-v1` : l'action 0 déplace le véhicule sur la gauche, 1 le déplace sur la droite.\n",
    "\n",
    "- ***Exécuter une action :***\n",
    "  - *exécution* : `observation, reward,done,info = env.step(action)`\n",
    "    - `observation`: ici la position et vitesse du 'Wagon' et du mat ([Wx, Wv, Ax, Mv])\n",
    "    - `reward`: utilité de l'état (récompense)\n",
    "    - `done` : booléen (True si but atteint)\n",
    "    - `info` : éventuelle information retournée par l'outil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wx=0.0m, \tWv=0.19, \tMangle=0.1° rad, \tMv=-0.26\n",
      "Wx=0.0039m, \tWv=0.39, \tMangle=0.095° rad, \tMv=-0.52\n",
      "Wx=0.012m, \tWv=0.58, \tMangle=0.084° rad, \tMv=-0.78\n",
      "Wx=0.023m, \tWv=0.77, \tMangle=0.069° rad, \tMv=-1.0\n",
      "Wx=0.039m, \tWv=0.97, \tMangle=0.048° rad, \tMv=-1.3\n",
      "Wx=0.058m, \tWv=1.2, \tMangle=0.022° rad, \tMv=-1.6\n",
      "Wx=0.081m, \tWv=1.4, \tMangle=-0.01° rad, \tMv=-1.9\n",
      "Wx=0.11m, \tWv=1.6, \tMangle=-0.048° rad, \tMv=-2.2\n",
      "Wx=0.14m, \tWv=1.7, \tMangle=-0.091° rad, \tMv=-2.5\n",
      "Wx=0.17m, \tWv=1.9, \tMangle=-0.14° rad, \tMv=-2.8\n",
      "________________________________\n"
     ]
    }
   ],
   "source": [
    "#test de 10 déplacements à droite\n",
    "env.env.state= np.array([0., 0., 0.1, 0.])\n",
    "action = 1\n",
    "for _ in range(0, 10):\n",
    "    env.render()\n",
    "    observation, reward, done, info = env.step(action)        \n",
    "    print(\"Wx={:2.2}m, \\tWv={:2.2}, \\tMangle={:2.2}° rad, \\tMv={:2.2}\".format(observation[0], observation[1], observation[2], observation[3]))\n",
    "print(\"________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wx=0.0m, \tWv=-0.2, \tMangle=0.0° rad, \tMv=0.29\n",
      "Wx=-0.0039m, \tWv=-0.39, \tMangle=0.0059° rad, \tMv=0.59\n",
      "Wx=-0.012m, \tWv=-0.59, \tMangle=0.018° rad, \tMv=0.88\n",
      "Wx=-0.023m, \tWv=-0.78, \tMangle=0.035° rad, \tMv=1.2\n",
      "Wx=-0.039m, \tWv=-0.98, \tMangle=0.059° rad, \tMv=1.5\n",
      "Wx=-0.059m, \tWv=-1.2, \tMangle=0.088° rad, \tMv=1.8\n",
      "Wx=-0.082m, \tWv=-1.4, \tMangle=0.12° rad, \tMv=2.1\n",
      "Wx=-0.11m, \tWv=-1.6, \tMangle=0.17° rad, \tMv=2.4\n",
      "Wx=-0.14m, \tWv=-1.8, \tMangle=0.22° rad, \tMv=2.8\n",
      "Wx=-0.18m, \tWv=-2.0, \tMangle=0.27° rad, \tMv=3.1\n",
      "________________________________\n"
     ]
    }
   ],
   "source": [
    "#test de 10 déplacements à gauche\n",
    "env.env.state= np.array([0., 0., 0, 0.])\n",
    "action = 0\n",
    "for _ in range(0, 10):\n",
    "    env.render()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(\"Wx={:2.2}m, \\tWv={:2.2}, \\tMangle={:2.2}° rad, \\tMv={:2.2}\".format(observation[0], observation[1], observation[2], observation[3]))\n",
    "print(\"________________________________\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### La récompense (reward) et le but\n",
    "Le *reward* dépend l'environnement d'exécution.. Dans `CartPole-v1`, un point est accordé par action, avec un seuil à 475\n",
    "\n",
    "Le *but* dans `CartPole-v0` est : \n",
    "  - que le mat reste le plus longtemps dans un angle de +-12° radian (0 étant la position verticale)\n",
    "  - que le wagon reste dans le cadre (position entre -4.8m et 4.8m)\n",
    "  - d'atteindre 500 actions (200 si l'environnement est `CartPole-v0`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test d'algorithme génétique\n",
    "## Test de programme évolutionnaire pour atteindre l'objectif\n",
    "- Utiliser donc l'environnement `CartPole-v1`\n",
    "- Programmez (en python) un algo génétique avec initialement les éléments suivants : \n",
    "  - sequence : tableau de valeurs entières 0 ou 1.\n",
    "  - 1 point de croisement (au centre)\n",
    "    - *(pour commencer, on pourrait proposer 2 points de croisement (au 1/3, et 2/3))*\n",
    "  - taille sequence : taille_seq = 50 initialement, puis, 100, 200, 500\n",
    "  - taille population initiale : taille_pop = 500, que l'on peut réduire ou augmenter\n",
    "  - taux de gènes mutants dans une séquence : taux_mut_seq = 0.1\n",
    "  - taux de séquences mutantes dans la population : taux_mut_pop = 0.2\n",
    "  - nombre max de cycles de reproductions : nb_cycles = 3000\n",
    "\n",
    "\n",
    "- Pour tester une séquence, il suffit de balayer le tableau et de lancer l'action correspondante..(en la transformant en un tableau de réel (1 -> [1.0])\n",
    "- Les 4 meilleures séquences (11,22,33,44) se reproduisent entre elles, donnant donc 12 fils : 12, 13, 14, 21, 23, 24, 31, 32, 34, 41, 42, 43.\n",
    "- Idéalement, un filtre doit permettre de supprimer les séquences identiques qui pourraient venir des croisements et des mutations.\n",
    "\n",
    "- Tester votre algo sur le nb de générations et afficher le rendu toutes les 100 générations et bien sûr le rendu de la meilleure séquence finale.\n",
    "  - (uniquement la position finale *colab*)\n",
    "  - (sous forme d'animation sous autre outil)\n",
    "\n",
    "\n",
    "- ***NB:*** \n",
    "  - Au plus simple il est possible d'utiliser une population (liste) de couples [sequence, utilite] où l'utilité serait la distance en x.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 0, 0, 0, 0, 0, 1, 1, 1, 1]), 0]\n",
      "arrive en x= -0.06 , fini= True\n",
      "couple [actions, arrivee] =  [array([1, 0, 0, 0, 0, 0, 1, 1, 1, 1]), 9.0]\n"
     ]
    }
   ],
   "source": [
    "#exemple :  \n",
    "env.reset()\n",
    "env.env.state= np.array([0, 0, 0.1, 0])\n",
    "tab = np.random.randint(0, 2, 10) \n",
    "couple = [tab, 0]\n",
    "print(couple)\n",
    "recompense = 0\n",
    "for a in couple[0]:\n",
    "    obs, reward, done, info = env.step(a)\n",
    "    if not done: recompense += reward\n",
    "print(\"arrive en x=\", round(obs[0],2), \", fini=\", done)\n",
    "couple[1] = recompense\n",
    "print(\"couple [actions, arrivee] = \", couple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Guide : \n",
    "- Créer votre fonction de récompense pour favoriser les séquences qui maintiennent le mat le plus longtemps dans la norme demandée (+-12°)\n",
    "- Basez vous sur l'exemple complet utilisant l'environnement Moutain-Car pour développer l'algorithme et fournir les courbes d'évolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
