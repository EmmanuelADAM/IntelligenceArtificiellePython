{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/DetectionAlertes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qF8xmpAdACr"
   },
   "source": [
    "# Détection d'alertes par réseaux de neurones\n",
    "\n",
    "Dans cet exercice, le but est de créer un système très basique de détection de messages douteux  par Réseaux de Neurones en se basant uniquement sur des mots clés trouvés dans les sujets de mails.\n",
    "\n",
    "Une version plus évoluée étudierait aussi le texte transormé en sac de mots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*L’observation du contenu des communications par les gouvernements dans un but de sécurité permettrait de détecter les mails potentiellement dangereux et de lever des alertes.\n",
    "Cependant la masse d’information échangée est trop importante pour garantir une bonne analyse.\n",
    "Des réseaux de neurones peuvent être utilisés pour guider la détection de problèmes potentiels.*\n",
    "\n",
    "*Il s’agit donc ici de définir un réseau de neurones et de lui faire apprendre à détecter des textes à risque.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les exemples d’apprentissage seront constitués :\n",
    "- d’une série de valeurs indiquant si oui ou non un terme est présent dans le texte analysé,\n",
    "- de la réponse attendue (dans la ligne danger)\n",
    "\n",
    "Pour chaque texte, des mots-clés sont détectés, et le danger potentiel du texte est indiqué. Voici les exemples d’apprentissage :\n",
    " - 'bombe', 'feu' => danger\n",
    " - 'bombe', 'patisserie' => _\n",
    " - 'bombe', 'acide' => danger\n",
    " - 'bombe', 'canon' => danger\n",
    " - 'fille', 'canon' => _\n",
    " - 'mec', 'canon' => _\n",
    " - 'patisserie', 'acide' => _\n",
    " - 'canon', 'balle' => danger\n",
    " - 'balle', 'tennis' => _\n",
    " - 'fille', 'acide' => danger\n",
    " \n",
    " Il faut transformer cela en un ensembles de vecteurs d'entrées et de sorties.\n",
    "\n",
    "| bombe | feu | patisserie | fille | canon | mec | acide | balle | tennis | *danger* |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| 1., | 1., | 0., | 0., | 0., | 0., | 0., | 0., | 0. |  1  |\n",
    "| 1., | 0., | 0., | 0., | 0., | 0., | 1., | 0., | 0. |  1  |\n",
    "| 1., | 0., | 0., | 0., | 1., | 0., | 0., | 0., | 0. |  1  |\n",
    "| 0., | 0., | 0., | 0., | 1., | 0., | 0., | 1., | 0. |  1  |\n",
    "| 0., | 0., | 0., | 1., | 0., | 0., | 1., | 0., | 0. |  1  |\n",
    "| 1., | 0., | 1., | 0., | 0., | 0., | 0., | 0., | 0. |  0  |\n",
    "| 0., | 0., | 0., | 1., | 1., | 0., | 0., | 0., | 0. |  0  |\n",
    "| 0., | 0., | 0., | 0., | 1., | 1., | 0., | 0., | 0. |  0  |\n",
    "| 0., | 0., | 1., | 0., | 0., | 0., | 1., | 0., | 0. |  0  |\n",
    "| 0., | 0., | 0., | 0., | 0., | 0., | 0., | 1., | 1. |  0  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZpJB9iOdRS3"
   },
   "source": [
    "---\n",
    "## Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odDg9S7xdFsv"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "#pour les graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "#SI bug plus loin lors du dessin des graphiques, ajouter ces 2 lignes\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XN8WXXdTdXx0"
   },
   "source": [
    "---\n",
    "\n",
    "### Définir les entrées et sorties attendues\n",
    "\n",
    "Les entrées correspondent aux présente des mots clés par sujet de mail.\n",
    "Ici, les entrées d'apprentissage sont consituées de 70% de l'exemple présenté (donc 9 lignes de  10 valeurs 0,1). Les sorties d'apprentissage correspondent au fait que chaque entrée soit un spam ou non.\n",
    "\n",
    "Les entrées et sorties de validations sont donc constitués des 40% restants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1mjGN2Bb5Ki"
   },
   "outputs": [],
   "source": [
    "#définissez les entrées sorties sur base du tableau\n",
    "tableau = np.array([[...], [...], ....], float) #remplissez les ... avec les valeurs de l'exemple\n",
    "\n",
    "#on prend un pourcentage de lignes pour apprendre, le reste pour valider\n",
    "#on mélange les lignes pour pouvoir avoir des exemples d'apprentissage\n",
    "# et de validation homogènes (au cas où les exemples auraient été saisis dans un ordre précis)\n",
    "# mais le mieux est de mieux choisir ces exemples qui ont un impact important dans la qualité de l'apprentissage\n",
    "np.random.shuffle(tableau)\n",
    "\n",
    "keywords = (\"bombe\", \"feu\", \"patisserie\", \"fille\", \"canon\", \"mec\", \"acide\", \"balle\", \"tennis\")    \n",
    "nb_lignes = tableau.shape[0]\n",
    "nb_val = len(keywords)\n",
    "\n",
    "#on décide que 70% des lignes sont des lignes d'apprentissage, le reste étant les lignes de validation\n",
    "nb_lignes_app = nb_lignes * 70 // 100\n",
    "nb_lignes_val = nb_lignes - nb_lignes_app\n",
    "\n",
    "#A FAIRE : \n",
    "# remplir les entrees et sorties d'apprentissage et de validation avec les bonnes valeurs\n",
    "\n",
    "# les \"nb_val\" premieres colonnes sont les entrees\n",
    "# entrees_app = ...\n",
    "# entrees_val = ...\n",
    "\n",
    "# la derniere colonne est la sortie\n",
    "# sorties_app = ...\n",
    "# sorties_val = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SC-1MnShdwe0"
   },
   "source": [
    "---\n",
    "\n",
    "### Choisir le modèle de réseau\n",
    "- ici les couches sont séquentielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbST4EmqcCdJ"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jo5Ej8kkd8nh"
   },
   "source": [
    "---\n",
    "\n",
    "### Définir l'architecture du réseau\n",
    "Choisissez la struture du réseau, le nb de couches cachées, etc.\n",
    "- une première couche composée de \n",
    "  - 10 neurones en entrée , plus le neurone BIAS (ou non)\n",
    "  - x neurones en sortie \n",
    "- une couche composée\n",
    "  - y neurones en entrée (ceux de la couche précédente) et \n",
    "  - de 1 neurone en sortie (Spam ou non)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avec_bias = True\n",
    "#une premiere couche constituée de 12 neurones en entrée, ...\n",
    "model.add(Dense(nb neurones en 1ere couche cachée, input_shape=(nb_val,), activation=celle que vous voulez))\n",
    "\n",
    "# si vous voulez plusieurs couches cachées, autant de add que nécessaire \n",
    "model.add(...)\n",
    "\n",
    "#une derniere couche constituée de 1 neurone en sortie, \n",
    "# nb neurones de la couche précédente en entrée et acivation sigmide\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8L4LxSBWeaF1"
   },
   "source": [
    "---\n",
    "\n",
    "### Compiler le  réseau\n",
    "- ici, on précise que l'algo de correction d'erreur est *'adam'*, et que l'erreur calculée est la moyenne des valeurs absolues des erreurs commises. On indique également que l'on veut voir apparaître en plus la précision de l'apprentissage (accuracy).\n",
    "\n",
    "(vous pouvez chosir un autre optimizer et un autre clacul de loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlnG97g7cQKW"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='MSE', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ4IQ-bIdtN1"
   },
   "source": [
    "---\n",
    "\n",
    "### Entraîner le réseau \n",
    "- ici on  le fait  'parler' (verbose=1), et on lance xx cycles d'apprentissage *(epochs à préciser)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "ddTla-J_cfz8",
    "outputId": "0fd3cade-cd59-41db-c5f6-0ea22e48cac0"
   },
   "outputs": [],
   "source": [
    "tests = model.fit(entrees_app, sorties_app, \n",
    "                    validation_data=(entrees_val, sorties_val),\n",
    "                    epochs=??, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0zBYIALlDYp"
   },
   "source": [
    "---\n",
    "\n",
    "## Dessiner l'évolution de l'erreur et de la pertinence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z89vptAXcuDM"
   },
   "outputs": [],
   "source": [
    "history_dict = tests.history\n",
    "eval_tests = list(history_dict.keys())\n",
    "print(\"les ensembles de valeurs récupérées lors des tests sont \")\n",
    "print(eval_tests)\n",
    "print(\"-> [perte sur exemple d'entrainement, qualité sur exemples d'entrainement,perte sur exemple de validation, qualité sur exemples de validation]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracer l'erreur d'entrainement / l'erreur de validation\n",
    "- L'erreur d'entrainement et l'erreur de validation doivent suivre des courbes quasi parallèle.\n",
    "- L'erreur d'entrainement doit être plus faible que l'erreur de validation\n",
    "    - si les courbes divergent, si la courbe de validation s'éloigne de la courbe d'entrainement, il y a alors un sur-apprentissage (overfitting) trop adapté aux données d'entrainement, sans doute trop poussé (diminuer les epochs?).\n",
    "    - s'il y a une erreur d'entrainement trop grande, il y a sous-apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history_dict[eval_tests[0]]\n",
    "val_loss = history_dict[eval_tests[2]]\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# draw the loss evolution in blue\n",
    "plt.plot(epochs, loss, 'b--', label='erreur sur exemples d\\'apprentissage')\n",
    "# draw the accuracy evolution in blue\n",
    "plt.plot(epochs, val_loss, 'r--', label='erreur sur exemples de validation')\n",
    "plt.title('Erreur')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Erreur')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict[eval_tests[1]]\n",
    "val_acc = history_dict[eval_tests[3]]\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# draw the loss evolution in blue\n",
    "plt.plot(epochs, acc, 'b--', label='précision sur exemples d\\'apprentissage')\n",
    "# draw the accuracy evolution in blue\n",
    "plt.plot(epochs, val_acc, 'r--', label='précision sur exemples de validation')\n",
    "plt.title('précision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('précision')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N38spzckmMMJ"
   },
   "source": [
    "---\n",
    "## Utilisation du réseau\n",
    "Quelle est la probabilité que les textes contenant les mots :\n",
    "1. bombe et feu\n",
    "2. mec patisserie feu\n",
    "\n",
    "soient des textes suspects ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entreesTests = np.array([ [...], [...], ...], float) # A FAIRE\n",
    "predictions = model.predict(entreesTests)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction des exemples\n",
    "\n",
    "On décide quand même que le texte contenant les mots « patisserie » et « feu » soit dangereux à plus de 95%.\n",
    "\n",
    "Ajouter une ou des lignes aux exemples d’entrainement.\n",
    "\n",
    "Relancer l’apprentissage du réseau et vérifier que les textes sont bien détecter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TestOUX.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
