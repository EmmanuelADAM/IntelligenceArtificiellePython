{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/TestET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qF8xmpAdACr"
   },
   "source": [
    "# Exemple d'apprentissage du ET avec TensorFlow\n",
    "## Illustration de l'importance du Bias\n",
    "\n",
    "|a|b|a et b|\n",
    "|:-:|:-:|:-:|\n",
    "|0|0|0|\n",
    "|0|1|0|\n",
    "|1|0|0|\n",
    "|1|1|1|\n",
    "\n",
    "\n",
    "*Théoriquement, en 1 couche, l'apprentissage du ET par réseau de neurones n'est pas possible.*\n",
    "\n",
    "En effet, la couche n'est consituée que de 1 neurone (1 sortie), ses entrées sont les valeurs `a` et `b`.\n",
    "`wa` et `wb` étant les poids affectés à ces valeurs, il faut vérifier : \n",
    " - `f(0)` tend vers 0 --> ok\n",
    " - `f(wb)` tend vers 0\n",
    " - `f(wa)` tend vers 0\n",
    " - `f(wa + wb)` tend vers 1 --> conflit avec les lignes précédentes\n",
    " \n",
    "*Vérifions le...*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZpJB9iOdRS3"
   },
   "source": [
    "---\n",
    "**Importer les librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odDg9S7xdFsv"
   },
   "outputs": [],
   "source": [
    "#keras : Python Deep Learning library\n",
    "import tensorflow.keras as keras\n",
    "#prevision d'utiliser un réseau en couches séquentielles\n",
    "from tensorflow.keras.models import Sequential\n",
    "#prevision d'utiliser des couches totalement connectées la précédente\n",
    "from tensorflow.keras.layers import Dense\n",
    "#utilisation de la classique librairie pour tableaux, ...\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XN8WXXdTdXx0"
   },
   "source": [
    "---\n",
    "\n",
    "## Définir les entrées et sorties attendues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1mjGN2Bb5Ki"
   },
   "outputs": [],
   "source": [
    "# a et b sont les seules entrées\n",
    "entrees = np.array([[0,0],[0,1],[1,0],[1,1]], float)\n",
    "\n",
    "# une seule sortie\n",
    "sorties = np.array([[0],[0],[0],[1]], float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SC-1MnShdwe0"
   },
   "source": [
    "---\n",
    "## 1. Version sans BIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Choisir le modèle de réseau \n",
    "***ici les couches sont séquentielles***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbST4EmqcCdJ"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jo5Ej8kkd8nh"
   },
   "source": [
    "### 1.2. Définir l'architecture du réseau\n",
    "- ici une seule couche constituée de 1 neurone en sortie, \n",
    "- de 2 neurones en entrée (pour chaque valeur), \n",
    "- utilisation de la sigmoïde comme fonction d'activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vr6dcOJicGYM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(1, input_dim=2, use_bias=False, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8L4LxSBWeaF1"
   },
   "source": [
    "---\n",
    "\n",
    "### 1.3. Compiler le  réseau\n",
    "Ici, on précise que \n",
    "  - l'algo de correction d'erreur est 'Adamax', \n",
    "  - l'erreur calculée est la moyenne des erreurs commises au carrées. $E = \\Sigma_{i=1 \\dots n}{(y^I_i - y_i)} / n$, $y^I_i$ sortie idéale attendue, $y_i$ sortie calculée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlnG97g7cQKW"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adamax', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ4IQ-bIdtN1"
   },
   "source": [
    "---\n",
    "\n",
    "### 1.4. Entraîner le réseau \n",
    "- ici on n'affiche pas les étapes de l'apprentissage, \n",
    "- et on lance 6000 cycles d'apprentissage (attendre entre 4 à 6mn !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ddTla-J_cfz8",
    "outputId": "3f251574-0acf-4b59-e480-3e736b427625"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23444d796a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(entrees, sorties, verbose=0, epochs=6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0zBYIALlDYp"
   },
   "source": [
    "---\n",
    "\n",
    "### 1.5. Vérifier le réseau\n",
    "Etape facultative, en général ***on teste le réseau sur d'autres exemples***. \n",
    "- Ici, on n'en a pas. Alors on lui demande de calculer la sortie pour chaque exemple de l'ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z89vptAXcuDM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(entrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5000722 ],\n",
       "       [0.51060617],\n",
       "       [0.51060617],\n",
       "       [0.92101085]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N38spzckmMMJ"
   },
   "source": [
    "---\n",
    "### 1.6. Affichage des résultats\n",
    "Ici pas de nécessité de graphique d'évolution de l'erreur.\n",
    "On affiche les entrées, la sortie attendue, la sortie calculée ainsi que les poids appliquées aux entrées et au signal bias.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "E7Lluiifcx0b",
    "outputId": "a68a8d3f-24f5-4f70-95fc-a215b158ee09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verification\n",
      "0.0  -  0.0  attendu  [0.]  trouvé  [0.5000722]\n",
      "0.0  -  1.0  attendu  [0.]  trouvé  [0.51060617]\n",
      "1.0  -  0.0  attendu  [0.]  trouvé  [0.51060617]\n",
      "1.0  -  1.0  attendu  [1.]  trouvé  [0.92101085]\n",
      "poids pour entree x =  5.0005126\n",
      "poids pour entree y =  5.0005136\n"
     ]
    }
   ],
   "source": [
    "def verification(bias=False):\n",
    "    print(\"verification\")\n",
    "    for i in range(0, len(entrees)):\n",
    "        print(entrees[i][0], \" - \", entrees[i][1], \" attendu \", sorties[i], \" trouvé \",  predictions[i])\n",
    "\n",
    "    ws = model.get_weights()\n",
    "    print(\"poids pour entree x = \" , ws[0][0][0])\n",
    "    print(\"poids pour entree y = \" , ws[0][1][0])\n",
    "    if(bias):print(\"poids pour bias = \", ws[1][0])\n",
    "\n",
    "verification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perte= 0.1944372057914734\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(entrees, sorties,verbose=0)\n",
    "print(\"perte=\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Des erreurs importantes donc**, comme prévu...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Version AVEC BIAS\n",
    "\n",
    "Le tableau est alors\n",
    "\n",
    "|bias|a|b|a et b|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|1|0|0|0|\n",
    "|1|0|1|0|\n",
    "|1|1|0|0|\n",
    "|1|1|1|1|\n",
    "\n",
    "\n",
    "*Théoriquement, en 1 couche, l'apprentissage du ET par réseau de neurones est alors possible.*\n",
    "\n",
    "En effet, la couche n'est constituée que de 1 neurone (1 sortie), ses entrées sont les valeurs `bias`, `a` et `b`.\n",
    "`wbias`, `wa` et `wb` étant les poids affectés à ces valeurs, il faut vérifier : \n",
    " - `f(bias)` tend vers 0\n",
    " - `f(bias + wb)` tend vers 0\n",
    " - `f(bias + wa)` tend vers 0\n",
    " - `f(bias + wa + wb)` tend vers 1 \n",
    " \n",
    "*Vérifions le...*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1. Définir l'architecture du réseau\n",
    "- ici une seule couche constituée de 1 neurone en sortie, \n",
    "- de 3 neurones en entrée (2 contenant les valeurs + **un Bias** (émettant toujours le signal 1)), \n",
    "- utilisation de la sigmoide comme fonction d'activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=2, use_bias=True, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2 Compiler et entraîner le  réseau \n",
    "Ici, on précise que \n",
    "  - l'algo de correction d'erreur est 'Adamax', \n",
    "  - l'erreur calculée utilise est la moyenne des erreurs au carrées \n",
    "  - on lance 6000 cycles d'apprentissage (attendre entre 4 à 6mn !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adamax', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.fit(entrees, sorties, verbose=0, epochs=6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2. Vérifier le réseau\n",
    "Pas d'exemples de validation, on vérifie simplement la correspondance entre sortie attendue et la sortie réelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "verification\n",
      "0.0  -  0.0  attendu  [0.]  trouvé  [0.00241795]\n",
      "0.0  -  1.0  attendu  [0.]  trouvé  [0.11837828]\n",
      "1.0  -  0.0  attendu  [0.]  trouvé  [0.11836719]\n",
      "1.0  -  1.0  attendu  [1.]  trouvé  [0.8814833]\n",
      "poids pour entree x =  4.0144305\n",
      "poids pour entree y =  4.014537\n",
      "poids pour bias =  -6.0224147\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(entrees)\n",
    "verification(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perte= 0.010519064962863922\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(entrees, sorties, verbose=0)\n",
    "print(\"perte=\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apprentissage quasi parfait !!!** \n",
    "- -> démonstration concrère de l'effet du `Bias` !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Utilisation\n",
    "Testons d'autres valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = np.array([[0.5,0.2], [0.9, 0.7], [0.1, 0.9]], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03870576],\n",
       "       [0.5988674 ],\n",
       "       [0.11837719]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(entrees, sorties):\n",
    "    for i in range(0, len(entrees)):\n",
    "        print(f\"apparition d'une données vraie à {entrees[i][0]*100:.2f}% et une vraie à {entrees[i][1]*100:.2f}% en même temps est possible à {sorties[i][0]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apparition d'une données vraie à 50.00% et une vraie à 20.00% en même temps est possible à 3.87%\n",
      "apparition d'une données vraie à 90.00% et une vraie à 70.00% en même temps est possible à 59.89%\n",
      "apparition d'une données vraie à 10.00% et une vraie à 90.00% en même temps est possible à 11.84%\n"
     ]
    }
   ],
   "source": [
    "print_predictions(tests, predictions)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TestET.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
